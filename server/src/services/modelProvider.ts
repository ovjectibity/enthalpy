import Anthropic from "@anthropic-ai/sdk";
import {
  ContentBlock,
  MessageParam,
  ContentBlockParam,
} from "@anthropic-ai/sdk/resources";
import Ajv, { JSONSchemaType } from 'ajv';
import { ModelMessage } from "./agent";
import { prompts } from "../contexts/mcprompts.js";
import { modelMessageSchema } from "../contexts/modelMessageSchema.js";

export interface LLMIntf {
  providerName: string,
  model: string;
  input: (msg: Array<ModelMessage>) => Promise<ModelMessage>
}

export class ClaudeIntf implements LLMIntf {
  providerName: string = "claude";
  model: string = "claude-haiku-4-5-20251001";
  // model: string = "claude-sonnet-4-5-20250929";
  maxTokens: number = 1024;
  client: Anthropic;
  validate: any;

  constructor() {
    if (process.env.ANTHROPIC_KEY === undefined) {
      console.log("Set the env variable ANTHROPIC_KEY");
    }
    this.client = new Anthropic({
      apiKey: process.env.ANTHROPIC_KEY,
    });
    const schema: JSONSchemaType<ModelMessage> = modelMessageSchema;
    const ajv = new Ajv();
    this.validate = ajv.compile(schema);
  }

  static translateToAnthropicMessage(msg: ModelMessage): MessageParam {
    let blocks = Array<ContentBlockParam>();
    msg.messages.forEach(m => {
      blocks.push({
        type: "text",
        text: JSON.stringify(m)
      });
    })
    return {
      role: msg.role,
      content: blocks
    }
  }

  static translateToAnthropicMessages(msgs: Array<ModelMessage>):
    Array<MessageParam> {
    let anthMsgs = Array<MessageParam>();
    msgs.forEach((msg2: ModelMessage) => {
      // console.log("DEBUGGING: model message2: ",  JSON.stringify(msg2));
      anthMsgs.push(ClaudeIntf.translateToAnthropicMessage(msg2));
    });
    return anthMsgs;
  }

  async input_test(): Promise<ModelMessage> {
    return {
        role: "assistant",
        messages: [
          {
            userContent: "Some content for the user generated by the agent."
          },
          {
            workflowContent: 
            {
              type: "workflow_context",
              content: "Some context gathered by the LLM"
            }
          }]
      };
  }

  async input(msgs: Array<ModelMessage>): Promise<ModelMessage> {
    // return this.input_test();
    // console.log("Sending these input messages: ",msgs);
    const message = await this.client.messages
      .create({
        max_tokens: this.maxTokens,
        messages: ClaudeIntf.translateToAnthropicMessages(msgs),
        model: this.model,
        system: prompts["system-prompt"]
      })
      .catch((error) => {
        console.log(error);
      });
    // console.log("Got this message from the claude model", message);
    //TODO: translate the content blocks to ModelMessage format
    if (message === undefined || message === null) {
      return Promise.resolve({
        role: "assistant",
        messages: []
      });
    } else {
      let msg: ModelMessage = {
        role: "assistant",
        messages: []
      };
      let contents = message.content as Array<ContentBlock>;
      contents.forEach((content: ContentBlock) => {
        if(content.type === "text") {
          if (content.text) {
            try {
            let modified = content.text.replace(/^```json|```$/g,"");
              let modifiedp: any = JSON.parse(modified);
              if(this.validate(modifiedp)) {
                // console.log("Model output conforms to the schema, got this messages array: ", 
                  // modifiedp.messages);
                let modifiedpv: ModelMessage = modifiedp as ModelMessage;
                msg.messages = msg.messages.concat(modifiedpv.messages);
              } else {
                console.log("Model output message does not conform to the schema");
              }
            } catch(e) {
              console.log(`Got LLM output ${content.text}`);
              console.log("Error when processing LLM response", e);
            }
          }
        }
      });
      return msg;
    }
  }
}
